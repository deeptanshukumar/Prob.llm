# prob.llm: Low-Resource RAG-based Study Assistant

This project aims to build a study assistant leveraging Retrieval Augmented Generation (RAG) for efficient knowledge retrieval from various document types.

## Features (Planned)
- Ingestion and querying of text from PDFs, Word documents, PowerPoint presentations, and standalone images (via OCR).
- Uses Gemma 3n as the local LLM and ChromaDB for vector storage.
- User-friendly local web application interface (Streamlit/Gradio).

## Setup
(Instructions will go here later, including Ollama setup)